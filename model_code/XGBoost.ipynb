{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b45bc7-40ee-407d-8ba1-10b2a791eea2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b677d59-2b6f-4131-b886-ac2db5ca8ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from geopy.distance import geodesic\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from xgboost import XGBRegressor\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# è¨­å®šåœ–è¡¨é¢¨æ ¼\n",
    "plt.rcParams['font.family'] = 'Microsoft JhengHei'\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "plt.rcParams['axes.titlesize'] = 14\n",
    "plt.rcParams['axes.labelsize'] = 12\n",
    "plt.rcParams['xtick.labelsize'] = 10\n",
    "plt.rcParams['ytick.labelsize'] = 10\n",
    "plt.rcParams['figure.figsize'] = (8, 6)\n",
    "plt.rcParams['figure.dpi'] = 100\n",
    "\n",
    "# 1. è®€å–è³‡æ–™èˆ‡ç‰¹å¾µå·¥ç¨‹\n",
    "df = pd.read_csv(r\"C:\\æª”å.csv\")\n",
    "df['e_time'] = pd.to_datetime(df['e_time'])\n",
    "df['Hour'] = df['e_time'].dt.hour\n",
    "df['Minute'] = df['e_time'].dt.minute\n",
    "df['Weekday'] = df['e_time'].dt.weekday\n",
    "\n",
    "# è¨ˆç®—è·é›¢\n",
    "target_lat, target_lon = 25.026622, 121.53006\n",
    "df['Distance'] = df.apply(\n",
    "    lambda row: geodesic((row['PositionLat'], row['PositionLon']), (target_lat, target_lon)).meters\n",
    "    if pd.notnull(row['PositionLat']) and pd.notnull(row['PositionLon']) else np.nan,\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# ç¯©é¸è³‡æ–™èˆ‡ç·¨ç¢¼è»Šç‰Œ\n",
    "df_filtered = df[df['Distance'] <= 20000].copy()\n",
    "df_filtered['PlateNumb_encoded'] = df_filtered['PlateNumb'].astype('category').cat.codes\n",
    "\n",
    "# ç‰¹å¾µæ¬„ä½å®šç¾©\n",
    "feature_cols_A = ['PlateNumb_encoded', 'Speed', 'Distance', 'rt_delay_sec', 'Hour', 'Minute', 'Weekday', \n",
    "                  'peak', 'daytype', 'rain', 'temp', 'wind', 'EstimateTime']\n",
    "feature_cols_B = ['PlateNumb_encoded', 'Speed', 'Distance', 'rt_delay_sec', 'Hour', 'Minute', 'Weekday', \n",
    "                  'peak', 'daytype', 'rain', 'temp', 'wind']\n",
    "\n",
    "# 2. è¨“ç·´èˆ‡è©•ä¼°æ¨¡å‹ï¼ˆæ¨¡å‹ A / Bï¼‰\n",
    "all_runs = {}\n",
    "\n",
    "for name, cols in [('æ¨¡å‹ A', feature_cols_A), ('æ¨¡å‹ B', feature_cols_B)]:\n",
    "    df_model = df_filtered.dropna(subset=cols + ['true_arrival_sec'])\n",
    "    df_model = df_model[(df_model['true_arrival_sec'] > 0) & (df_model['true_arrival_sec'] < 5000)]\n",
    "\n",
    "    X = df_model[cols]\n",
    "    y = df_model['true_arrival_sec']\n",
    "\n",
    "    maes, rmses, r2s, models = [], [], [], []\n",
    "    all_preds = []\n",
    "\n",
    "    for i in range(20):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X, y, test_size=0.2, shuffle=True, random_state=i\n",
    "        )\n",
    "\n",
    "        model = XGBRegressor(n_estimators=100, max_depth=6, learning_rate=0.1, random_state=i)\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "\n",
    "        maes.append(mean_absolute_error(y_test, y_pred))\n",
    "        rmses.append(np.sqrt(mean_squared_error(y_test, y_pred)))\n",
    "        r2s.append(r2_score(y_test, y_pred))\n",
    "        models.append(model)\n",
    "        all_preds.append((y_test, y_pred))\n",
    "\n",
    "    avg_mae, avg_rmse, avg_r2 = np.mean(maes), np.mean(rmses), np.mean(r2s)\n",
    "    distances = [(mae - avg_mae)**2 + (rmse - avg_rmse)**2 + (r2 - avg_r2)**2\n",
    "                 for mae, rmse, r2 in zip(maes, rmses, r2s)]\n",
    "    best_index = int(np.argmin(distances))\n",
    "    best_model = models[best_index]\n",
    "    y_test_best, y_pred_best = all_preds[best_index]\n",
    "\n",
    "    all_runs[name] = {\n",
    "        'å¹³å‡ MAE': round(avg_mae, 2),\n",
    "        'MAE æ¨™æº–å·®': round(np.std(maes), 2),\n",
    "        'å¹³å‡ RMSE': round(avg_rmse, 2),\n",
    "        'RMSE æ¨™æº–å·®': round(np.std(rmses), 2),\n",
    "        'å¹³å‡ RÂ²': round(avg_r2, 4),\n",
    "        'RÂ² æ¨™æº–å·®': round(np.std(r2s), 4),\n",
    "        'æœ€ä½³æ¨¡å‹ index': best_index,\n",
    "        'æœ€ä½³ MAE': round(maes[best_index], 2),\n",
    "        'æœ€ä½³ RMSE': round(rmses[best_index], 2),\n",
    "        'æœ€ä½³ RÂ²': round(r2s[best_index], 4),\n",
    "        'æœ€ä½³æ¨¡å‹ç‰©ä»¶': best_model,\n",
    "        'æœ€ä½³é æ¸¬å°ç…§': (y_test_best, y_pred_best)\n",
    "    }\n",
    "\n",
    "# 3. å°å‡ºçµæœ\n",
    "for name, res in all_runs.items():\n",
    "    print(f\"\\nğŸ“Š {name}\")\n",
    "    for k, v in res.items():\n",
    "        if k not in ['æœ€ä½³æ¨¡å‹ç‰©ä»¶', 'æœ€ä½³é æ¸¬å°ç…§']:\n",
    "            print(f\"{k}: {v}\")\n",
    "\n",
    "# 4. é æ¸¬ vs çœŸå¯¦å€¼ åœ–ï¼ˆæ¨¡å‹ A / Bï¼‰â€” ç¬¦åˆç°¡å ±é¢¨æ ¼ï¼ˆèƒŒæ™¯æ·ºæ£•ï¼‰\n",
    "for name in ['æ¨¡å‹ A', 'æ¨¡å‹ B']:\n",
    "    y_test_best, y_pred_best = all_runs[name]['æœ€ä½³é æ¸¬å°ç…§']\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(6.5, 5))\n",
    "    fig.patch.set_facecolor('#f5f0e6')  # æ•´å€‹åœ–èƒŒæ™¯\n",
    "    ax.set_facecolor('#f5f0e6')         # åœ–å€åŸŸèƒŒæ™¯\n",
    "\n",
    "    ax.scatter(y_test_best, y_pred_best, alpha=0.7, color='#c1a47e', edgecolor='none')\n",
    "    ax.plot([y_test_best.min(), y_test_best.max()],\n",
    "            [y_test_best.min(), y_test_best.max()], 'k--', linewidth=1.2)\n",
    "\n",
    "    ax.set_xlabel(\"å¯¦éš›åˆ°ç«™æ™‚é–“ (ç§’)\", color='black')\n",
    "    ax.set_ylabel(\"é æ¸¬åˆ°ç«™æ™‚é–“ (ç§’)\", color='black')\n",
    "    ax.set_title(f\"{name} - é æ¸¬èˆ‡å¯¦éš›æ¯”è¼ƒ\", pad=12, color='black')\n",
    "\n",
    "    ax.grid(True, linestyle='--', linewidth=0.5, alpha=0.4)\n",
    "    ax.tick_params(colors='black')\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    filename = f\"C:/Users/{name.strip()}_scatter.png\"\n",
    "    plt.savefig(filename, dpi=300)\n",
    "    plt.show()\n",
    "\n",
    "# 5. ç‰¹å¾µé‡è¦æ€§ï¼ˆåªå°å‡ºæ•¸å­—ï¼Œä¸ç•«åœ–ï¼‰\n",
    "for name in ['æ¨¡å‹ A', 'æ¨¡å‹ B']:\n",
    "    model = all_runs[name]['æœ€ä½³æ¨¡å‹ç‰©ä»¶']\n",
    "    cols = feature_cols_A if name == 'æ¨¡å‹ A' else feature_cols_B\n",
    "    importance = model.feature_importances_\n",
    "    importance_series = pd.Series(importance, index=cols).sort_values(ascending=False)\n",
    "\n",
    "    print(f\"\\nğŸ” {name} ç‰¹å¾µé‡è¦æ€§ï¼ˆç”±é«˜åˆ°ä½ï¼‰:\")\n",
    "    for i, (feature, score) in enumerate(importance_series.items(), 1):\n",
    "        print(f\"{i}. {feature}ï¼š{round(score, 4)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27bee071-f6db-4baf-bccf-749222618be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from geopy.distance import geodesic\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from xgboost import XGBRegressor\n",
    "import pickle\n",
    "\n",
    "# 1. è®€å–è³‡æ–™èˆ‡ç‰¹å¾µå·¥ç¨‹\n",
    "df = pd.read_csv(r\"C:\\Users\\æª”å.csv\")\n",
    "df['e_time'] = pd.to_datetime(df['e_time'])\n",
    "df['Hour'] = df['e_time'].dt.hour\n",
    "df['Minute'] = df['e_time'].dt.minute\n",
    "df['Weekday'] = df['e_time'].dt.weekday\n",
    "\n",
    "# è¨ˆç®—è·é›¢\n",
    "target_lat, target_lon = 25.026622, 121.53006\n",
    "df['Distance'] = df.apply(\n",
    "    lambda row: geodesic((row['PositionLat'], row['PositionLon']), (target_lat, target_lon)).meters\n",
    "    if pd.notnull(row['PositionLat']) and pd.notnull(row['PositionLon']) else np.nan,\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# ç¯©é¸è³‡æ–™èˆ‡ç·¨ç¢¼è»Šç‰Œ\n",
    "df_filtered = df[df['Distance'] <= 20000].copy()\n",
    "df_filtered['PlateNumb_encoded'] = df_filtered['PlateNumb'].astype('category').cat.codes\n",
    "\n",
    "# ç‰¹å¾µæ¬„ä½å®šç¾©\n",
    "feature_cols_A = ['PlateNumb_encoded', 'Speed', 'Distance', 'rt_delay_sec', 'Hour', 'Minute', 'Weekday', \n",
    "                  'peak', 'daytype', 'rain', 'temp', 'wind', 'EstimateTime']\n",
    "feature_cols_B = ['PlateNumb_encoded', 'Speed', 'Distance', 'rt_delay_sec', 'Hour', 'Minute', 'Weekday', \n",
    "                  'peak', 'daytype', 'rain', 'temp', 'wind']\n",
    "\n",
    "# 2. è¨“ç·´èˆ‡è©•ä¼°æ¨¡å‹\n",
    "all_runs = {}\n",
    "\n",
    "for name, cols in [('æ¨¡å‹ A (å« EstimateTime)', feature_cols_A),\n",
    "                   ('æ¨¡å‹ B (ä¸å« EstimateTime)', feature_cols_B)]:\n",
    "\n",
    "    df_model = df_filtered.dropna(subset=cols + ['true_arrival_sec'])\n",
    "    X = df_model[cols]\n",
    "    y = df_model['true_arrival_sec']\n",
    "\n",
    "    maes, rmses, r2s, models = [], [], [], []\n",
    "\n",
    "    for i in range(20):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X, y, test_size=0.2, shuffle=True, random_state=i\n",
    "        )\n",
    "\n",
    "        model = XGBRegressor(n_estimators=100, max_depth=6, learning_rate=0.1, random_state=i)\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "\n",
    "        maes.append(mean_absolute_error(y_test, y_pred))\n",
    "        rmses.append(np.sqrt(mean_squared_error(y_test, y_pred)))\n",
    "        r2s.append(r2_score(y_test, y_pred))\n",
    "        models.append(model)\n",
    "\n",
    "    # å¹³å‡èˆ‡æœ€æ¥è¿‘å¹³å‡çš„ä¸€æ¬¡\n",
    "    avg_mae, avg_rmse, avg_r2 = np.mean(maes), np.mean(rmses), np.mean(r2s)\n",
    "    distances = [(mae - avg_mae)**2 + (rmse - avg_rmse)**2 + (r2 - avg_r2)**2\n",
    "                 for mae, rmse, r2 in zip(maes, rmses, r2s)]\n",
    "    best_index = int(np.argmin(distances))\n",
    "    best_model = models[best_index]\n",
    "\n",
    "    all_runs[name] = {\n",
    "        'å¹³å‡ MAE': round(avg_mae, 2),\n",
    "        'MAE æ¨™æº–å·®': round(np.std(maes), 2),\n",
    "        'å¹³å‡ RMSE': round(avg_rmse, 2),\n",
    "        'RMSE æ¨™æº–å·®': round(np.std(rmses), 2),\n",
    "        'å¹³å‡ RÂ²': round(avg_r2, 4),\n",
    "        'RÂ² æ¨™æº–å·®': round(np.std(r2s), 4),\n",
    "        'æœ€ä½³æ¨¡å‹ index': best_index,\n",
    "        'æœ€ä½³ MAE': round(maes[best_index], 2),\n",
    "        'æœ€ä½³ RMSE': round(rmses[best_index], 2),\n",
    "        'æœ€ä½³ RÂ²': round(r2s[best_index], 4),\n",
    "        'æœ€ä½³æ¨¡å‹ç‰©ä»¶': best_model\n",
    "    }\n",
    "\n",
    "# å–å¾—ç•¶å‰çš„ PlateNumb å°æ‡‰è¡¨\n",
    "plate_categories = df_filtered['PlateNumb'].astype('category').cat.categories\n",
    "plate_mapping = {v: i for i, v in enumerate(plate_categories)}\n",
    "\n",
    "# 3. å°å‡ºçµæœ\n",
    "for name, res in all_runs.items():\n",
    "    print(f\"\\nğŸ“Š {name}\")\n",
    "    for k, v in res.items():\n",
    "        if k != 'æœ€ä½³æ¨¡å‹ç‰©ä»¶':\n",
    "            print(f\"{k}: {v}\")\n",
    "\n",
    "#4. å„²å­˜ç‚º .pkl\n",
    "# åŒ…æˆä¸€å€‹ dict ä¸€èµ·å­˜é€² pkl\n",
    "# æ‰¾å‡ºæœ€å¸¸å‡ºç¾çš„è»Šç‰Œ\n",
    "most_common_plate = df_filtered['PlateNumb'].value_counts().idxmax()\n",
    "default_encoded = plate_mapping[most_common_plate]\n",
    "\n",
    "# åŒ…å« fallback ç·¨ç¢¼è³‡è¨Šçš„æ¨¡å‹å„²å­˜åŒ…\n",
    "modelA_pack = {\n",
    "    'model': all_runs['æ¨¡å‹ A (å« EstimateTime)']['æœ€ä½³æ¨¡å‹ç‰©ä»¶'],\n",
    "    'plate_mapping': plate_mapping,\n",
    "    'default_plate': most_common_plate,\n",
    "    'default_encoded': default_encoded\n",
    "}\n",
    "\n",
    "modelB_pack = {\n",
    "    'model': all_runs['æ¨¡å‹ B (ä¸å« EstimateTime)']['æœ€ä½³æ¨¡å‹ç‰©ä»¶'],\n",
    "    'plate_mapping': plate_mapping,\n",
    "    'default_plate': most_common_plate,\n",
    "    'default_encoded': default_encoded\n",
    "}\n",
    "\n",
    "# å„²å­˜ç‚º .pkl æª”\n",
    "with open(r\"C:\\Users\\æ¬²å­˜æˆæª”å\", \"wb\") as f:\n",
    "    pickle.dump(modelA_pack, f)\n",
    "\n",
    "with open(r\"C:\\Users\\æ¬²å­˜æˆæª”å\", \"wb\") as f:\n",
    "    pickle.dump(modelB_pack, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
