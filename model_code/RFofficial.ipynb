{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1177143-4b2a-411e-b1dd-58269399211c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# è®€å–ä½ ä¹‹å‰å„²å­˜çš„åˆä½µè³‡æ–™æª”æ¡ˆ\n",
    "df = pd.read_csv(r\"C:\\Users\\æª”å.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a743f44b-2f51-4565-b195-ff6904a0b665",
   "metadata": {},
   "outputs": [],
   "source": [
    "# æŠŠ e_time è½‰æˆ datetime æ ¼å¼\n",
    "df['e_time'] = pd.to_datetime(df['e_time'])\n",
    "\n",
    "# æ‹†å‡ºæ™‚é–“ç‰¹å¾µ\n",
    "df['Hour'] = df['e_time'].dt.hour\n",
    "df['Minute'] = df['e_time'].dt.minute\n",
    "df['Weekday'] = df['e_time'].dt.weekday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f95eec-0c73-45ce-884e-a474d24e551f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from geopy.distance import geodesic\n",
    "\n",
    "# ä½¿ç”¨å®˜æ–¹æä¾›çš„å¸«å¤§ç¶œåˆå¤§æ¨“ç«™ç‰Œåº§æ¨™\n",
    "target_lat, target_lon = 25.026622, 121.53006  # æ³¨æ„ï¼šç·¯åº¦åœ¨å‰ï¼Œç¶“åº¦åœ¨å¾Œ\n",
    "\n",
    "# åŠ å…¥è·é›¢æ¬„ä½ï¼ˆå–®ä½ï¼šå…¬å°ºï¼‰\n",
    "df['Distance'] = df.apply(\n",
    "    lambda row: geodesic((row['PositionLat'], row['PositionLon']), (target_lat, target_lon)).meters\n",
    "    if pd.notnull(row['PositionLat']) and pd.notnull(row['PositionLon']) else np.nan,\n",
    "    axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61012372-1c9b-4578-9d2a-1a2f17dd07a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# å‡è¨­ä½ çš„ DataFrame åå« df\n",
    "df_filtered = df[df['Distance'] <= 20000].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b245051-b8a0-4110-b9fe-3ab61fe16454",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered['PlateNumb_encoded'] = df_filtered['PlateNumb'].astype('category').cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7e4eb55-f4d0-4cd4-97c2-be51da851043",
   "metadata": {},
   "outputs": [],
   "source": [
    "# å« EstimateTime çš„ç‰¹å¾µçµ„ï¼ˆæ¨¡å‹ Aï¼‰\n",
    "feature_cols_A = ['PlateNumb_encoded','Speed', 'Distance', 'rt_delay_sec', 'Hour', 'Minute', 'Weekday', \n",
    "                  'peak', 'daytype', 'rain', 'temp', 'wind', 'EstimateTime']\n",
    "\n",
    "# ä¸å« EstimateTime çš„ç‰¹å¾µçµ„ï¼ˆæ¨¡å‹ Bï¼‰\n",
    "feature_cols_B = ['PlateNumb_encoded','Speed', 'Distance', 'rt_delay_sec','Hour', 'Minute', 'Weekday', \n",
    "                  'peak', 'daytype', 'rain', 'temp', 'wind']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9e6a6b2-3bcc-426f-af1e-00cd34356b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "# æº–å‚™è³‡æ–™\n",
    "# å…ˆéæ¿¾ true_arrival_sec < 5000 çš„è³‡æ–™\n",
    "df_limited = df_filtered[df_filtered['true_arrival_sec'] < 5000]\n",
    "\n",
    "# æº–å‚™è³‡æ–™\n",
    "X = df_limited[feature_cols_A]\n",
    "y = df_limited['true_arrival_sec']\n",
    "\n",
    "def run_rf_model(X, y, feature_names, model_name):\n",
    "    maes, rmses, r2s, models = [], [], [], []\n",
    "\n",
    "    for i in range(20):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X, y, test_size=0.2, shuffle=True, random_state=i\n",
    "        )\n",
    "\n",
    "        model = RandomForestRegressor(n_estimators=100, random_state=i)\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "\n",
    "        maes.append(mean_absolute_error(y_test, y_pred))\n",
    "        rmses.append(np.sqrt(mean_squared_error(y_test, y_pred)))\n",
    "        r2s.append(r2_score(y_test, y_pred))\n",
    "        models.append(model)\n",
    "\n",
    "    # å¹³å‡èˆ‡æ‰¾å‡ºæœ€æ¥è¿‘å¹³å‡çš„ä¸€æ¬¡\n",
    "    avg_mae, avg_rmse, avg_r2 = np.mean(maes), np.mean(rmses), np.mean(r2s)\n",
    "    distances = [(mae - avg_mae)**2 + (rmse - avg_rmse)**2 + (r2 - avg_r2)**2\n",
    "                 for mae, rmse, r2 in zip(maes, rmses, r2s)]\n",
    "    best_index = int(np.argmin(distances))\n",
    "    best_model = models[best_index]\n",
    "\n",
    "    # å°å‡ºçµæœ\n",
    "    print(f\"\\nğŸŒ² {model_name}ï¼ˆ295ï¼‰\")\n",
    "    print(f\"å¹³å‡ MAE: {avg_mae:.2f} Â± {np.std(maes):.2f}\")\n",
    "    print(f\"å¹³å‡ RMSE: {avg_rmse:.2f} Â± {np.std(rmses):.2f}\")\n",
    "    print(f\"å¹³å‡ RÂ²: {avg_r2:.4f} Â± {np.std(r2s):.4f}\")\n",
    "    print(f\"\\nğŸ” æœ€ä½³æ¨¡å‹ç‰¹å¾µé‡è¦æ€§ï¼ˆç¬¬ {best_index} æ¬¡ï¼‰ï¼š\")\n",
    "    for name, importance in zip(feature_names, best_model.feature_importances_):\n",
    "        print(f\"{name}: {importance:.4f}\")\n",
    "\n",
    "# åŸ·è¡Œ RF æ¨¡å‹ Aï¼ˆå« EstimateTimeï¼‰\n",
    "run_rf_model(X, y, feature_cols_A, \"Random Forest æ¨¡å‹ Aï¼ˆå« EstimateTimeï¼‰\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2973b55d-4223-4c22-a631-caa5c52b4d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# æº–å‚™æ¨¡å‹ B çš„è³‡æ–™\n",
    "df_limited = df_filtered[df_filtered['true_arrival_sec'] < 5000]\n",
    "\n",
    "# æº–å‚™è³‡æ–™\n",
    "X_B = df_limited[feature_cols_B]\n",
    "y = df_limited['true_arrival_sec']\n",
    "\n",
    "def run_rf_model_B(X, y, feature_names, model_name):\n",
    "    maes, rmses, r2s, models = [], [], [], []\n",
    "\n",
    "    for i in range(20):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X, y, test_size=0.2, shuffle=True, random_state=i\n",
    "        )\n",
    "\n",
    "        model = RandomForestRegressor(n_estimators=100, random_state=i)\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "\n",
    "        maes.append(mean_absolute_error(y_test, y_pred))\n",
    "        rmses.append(np.sqrt(mean_squared_error(y_test, y_pred)))\n",
    "        r2s.append(r2_score(y_test, y_pred))\n",
    "        models.append(model)\n",
    "\n",
    "    # å¹³å‡èˆ‡æ‰¾å‡ºæœ€æ¥è¿‘å¹³å‡çš„ä¸€æ¬¡\n",
    "    avg_mae, avg_rmse, avg_r2 = np.mean(maes), np.mean(rmses), np.mean(r2s)\n",
    "    distances = [(mae - avg_mae)**2 + (rmse - avg_rmse)**2 + (r2 - avg_r2)**2\n",
    "                 for mae, rmse, r2 in zip(maes, rmses, r2s)]\n",
    "    best_index = int(np.argmin(distances))\n",
    "    best_model = models[best_index]\n",
    "\n",
    "    # å°å‡ºçµæœ\n",
    "    print(f\"\\nğŸŒ² {model_name}ï¼ˆ295ï¼‰\")\n",
    "    print(f\"å¹³å‡ MAE: {avg_mae:.2f} Â± {np.std(maes):.2f}\")\n",
    "    print(f\"å¹³å‡ RMSE: {avg_rmse:.2f} Â± {np.std(rmses):.2f}\")\n",
    "    print(f\"å¹³å‡ RÂ²: {avg_r2:.4f} Â± {np.std(r2s):.4f}\")\n",
    "    print(f\"\\nğŸ” æœ€ä½³æ¨¡å‹ç‰¹å¾µé‡è¦æ€§ï¼ˆç¬¬ {best_index} æ¬¡ï¼‰ï¼š\")\n",
    "    for name, importance in zip(feature_names, best_model.feature_importances_):\n",
    "        print(f\"{name}: {importance:.4f}\")\n",
    "\n",
    "# åŸ·è¡Œ RF æ¨¡å‹ Bï¼ˆä¸å« EstimateTimeï¼‰\n",
    "run_rf_model_B(X_B, y, feature_cols_B, \"Random Forest æ¨¡å‹ Bï¼ˆä¸å« EstimateTimeï¼‰\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea4a0b87-ea0f-4c6f-96b5-bf01cb743daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# å–å¾—æ¨¡å‹ A çš„è³‡æ–™\n",
    "model_A = results['æ¨¡å‹ A (å« EstimateTime)']['model']\n",
    "features_A = results['æ¨¡å‹ A (å« EstimateTime)']['features']\n",
    "importances_A = model_A.feature_importances_\n",
    "\n",
    "# æ’åºä¸¦é¡¯ç¤º\n",
    "sorted_idx = np.argsort(importances_A)[::-1]\n",
    "\n",
    "print(\"æ¨¡å‹ Aï¼ˆå« EstimateTimeï¼‰ç‰¹å¾µé‡è¦æ€§æ’åï¼š\\n\")\n",
    "for i in sorted_idx:\n",
    "    print(f\"{features_A[i]:<10s}  â†’  {importances_A[i]:.4f}\")\n",
    "    \n",
    "# å–å¾—æ¨¡å‹ B çš„è³‡æ–™\n",
    "model_B = results['æ¨¡å‹ B (ä¸å« EstimateTime)']['model']\n",
    "features_B = results['æ¨¡å‹ B (ä¸å« EstimateTime)']['features']\n",
    "importances_B = model_B.feature_importances_\n",
    "\n",
    "# æ’åºä¸¦é¡¯ç¤º\n",
    "sorted_idx = np.argsort(importances_B)[::-1]\n",
    "\n",
    "print(\"æ¨¡å‹ Bï¼ˆä¸å« EstimateTimeï¼‰ç‰¹å¾µé‡è¦æ€§æ’åï¼š\\n\")\n",
    "for i in sorted_idx:\n",
    "    print(f\"{features_B[i]:<10s}  â†’  {importances_B[i]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce7da55c-3903-49d7-ba14-fa989fb0a302",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "joblib.dump(model_A, r'C:\\Users\\æ¬²å­˜æˆæª”å.pkl')\n",
    "joblib.dump(model_B, r'C:\\Users\\æ¬²å­˜æˆæª”å.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
